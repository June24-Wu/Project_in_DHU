{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center>第四章 4-2 大数据采集-Scrapy</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义爬虫的任务\n",
    "\n",
    "## 涉及的语法\n",
    "语法涉及类（面向对象）、列表list、字典dict、循环、函数、字符串操作、文件读写\n",
    "\n",
    "## 概述\n",
    "这个爬虫的任务是爬取http://quotes.toscrape.com/page/1/ 的前两页，提取每条名言的文字内容，作者和标签，最后以JSON格式保存到文件中\n",
    "\n",
    "\n",
    "## 如何修改\n",
    "\n",
    "在自己做定制时，只需要修改`__init__`和`parse`两个方法，通俗讲__init__方法决定了爬取哪些网站，parse则指明了在每一个网页上爬取哪些内容\n",
    "- init: 设置待爬取网站的列表和保存文件路径，其中变量self.urls是待爬取网站的列表，self.file是一个文件对象\n",
    "- parse：方法内是针对每个url成功访问之后进行的页面解析\n",
    "   关于如何解析具体网页，也就是选择器的使用，与网页格式十分相关，这个样例无法适用于其他网站。由于选择器的使用有很大的选择性，所以可以参考文档http://scrapy-chs.readthedocs.io/zh_CN/latest/topics/selectors.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法：Scrapy框架 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    \n",
    "    name = \"spider\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self):    #设置待爬取网站的列表和保存文件路径\n",
    "        \n",
    "        self.file = open('demo1_quotes.json', 'w');    #文件对象\n",
    "        \n",
    "        #设置待爬取网站列表\n",
    "        self.urls = []\n",
    "        for i in range(1,3):\n",
    "            self.urls.append('http://quotes.toscrape.com/page/' + str(i) )\n",
    "            \n",
    "#       初始化效果 效果等同\n",
    "#         self.urls = [\n",
    "#             'http://quotes.toscrape.com/page/1/',\n",
    "#             'http://quotes.toscrape.com/page/2/',\n",
    "#         ]\n",
    "        \n",
    "        print(self.urls)\n",
    "\n",
    "        \n",
    "    def start_requests(self):\n",
    "        #self.init_urls()\n",
    "        for url in self.urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)    \n",
    "    \n",
    "\n",
    "    #parse方法会在每个request收到response之后调用,方法内是针对每个url成功访问之后进行的页面解析\n",
    "    def parse(self, response):\n",
    "#         parse(self, response) 中的response是HtmlResponse 类型的,可以用css选择器或者xpath选择器\n",
    "\n",
    "        #提取名言列表\n",
    "        quotes = response.css(\"div.quote\");     #css选择器\n",
    "#         quotes = response.xpath(\"//div[@class='quote']\");  #引号要注意\n",
    "    \n",
    "        for quote in quotes:\n",
    "            #提取名言的文字内容\n",
    "            text = quote.css(\".text::text\").extract_first();   #提取第一条\n",
    "            #提取每条名言中的作者名\n",
    "            author = quote.css(\"small.author::text\").extract_first();\n",
    "            #提取名言标签\n",
    "            tags = quote.css(\".tags .tag::text\").extract();    #提取所有的\n",
    "        \n",
    "            #构建字典对象\n",
    "            item = {\"author\":author, \"text\": text, \"tags\":tags };\n",
    "            #将字典转换成json字符串\n",
    "            line = json.dumps(dict(item))\n",
    "            #将每个条目写入文件\n",
    "            self.file.write(line + \"\\n\")\n",
    "        #及时将内容写入文件，否则可能会出现少许延迟\n",
    "        self.file.flush()\n",
    "        os.fsync(self.file)\n",
    "        #输出当前解析完成的网页网址，可以当做爬取进度来看待,与程序逻辑无关\n",
    "        print(\"over: \" + response.url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 执行爬虫任务\n",
    "启动后，将执行Myspider。\n",
    "这部分的代码块，如果确实非常了解scrapy的运行机制，那么可以做定制，否则不建议自行修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-29 11:48:47 [scrapy.utils.log] INFO: Scrapy 1.7.3 started (bot: scrapybot)\n",
      "2020-05-29 11:48:47 [scrapy.utils.log] INFO: Versions: lxml 4.4.1.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.7.0, Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.17763-SP0\n",
      "2020-05-29 11:48:47 [scrapy.crawler] INFO: Overridden settings: {'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
      "2020-05-29 11:48:47 [scrapy.extensions.telnet] INFO: Telnet Password: d4010be694d9647a\n",
      "2020-05-29 11:48:47 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://quotes.toscrape.com/page/1', 'http://quotes.toscrape.com/page/2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-29 11:48:49 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2020-05-29 11:48:49 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2020-05-29 11:48:49 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2020-05-29 11:48:49 [scrapy.core.engine] INFO: Spider opened\n",
      "2020-05-29 11:48:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2020-05-29 11:48:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2020-05-29 11:48:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://quotes.toscrape.com/page/2/> from <GET http://quotes.toscrape.com/page/2>\n",
      "2020-05-29 11:48:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://quotes.toscrape.com/page/1/> from <GET http://quotes.toscrape.com/page/1>\n",
      "2020-05-29 11:48:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/2/> (referer: None)\n",
      "2020-05-29 11:48:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)\n",
      "2020-05-29 11:48:51 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2020-05-29 11:48:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 962,\n",
      " 'downloader/request_count': 4,\n",
      " 'downloader/request_method_count/GET': 4,\n",
      " 'downloader/response_bytes': 26135,\n",
      " 'downloader/response_count': 4,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'downloader/response_status_count/301': 2,\n",
      " 'elapsed_time_seconds': 1.931945,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2020, 5, 29, 3, 48, 51, 132153),\n",
      " 'log_count/DEBUG': 4,\n",
      " 'log_count/INFO': 10,\n",
      " 'response_received_count': 2,\n",
      " 'scheduler/dequeued': 4,\n",
      " 'scheduler/dequeued/memory': 4,\n",
      " 'scheduler/enqueued': 4,\n",
      " 'scheduler/enqueued/memory': 4,\n",
      " 'start_time': datetime.datetime(2020, 5, 29, 3, 48, 49, 200208)}\n",
      "2020-05-29 11:48:51 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over: http://quotes.toscrape.com/page/2/\n",
      "over: http://quotes.toscrape.com/page/1/\n"
     ]
    }
   ],
   "source": [
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.crawl(MySpider)\n",
    "process.start() # 这句代码就是开始了整个爬虫过程 ，会输出一大堆信息，可以无视"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 破译反爬虫\n",
    "- 分布式爬虫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json文件中有20行数据\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'author': 'Marilyn Monroe',\n",
       "  'text': \"“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\",\n",
       "  'tags': ['friends',\n",
       "   'heartbreak',\n",
       "   'inspirational',\n",
       "   'life',\n",
       "   'love',\n",
       "   'sisters']},\n",
       " {'author': 'J.K. Rowling',\n",
       "  'text': '“It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.”',\n",
       "  'tags': ['courage', 'friends']},\n",
       " {'author': 'Albert Einstein',\n",
       "  'text': \"“If you can't explain it to a six year old, you don't understand it yourself.”\",\n",
       "  'tags': ['simplicity', 'understand']},\n",
       " {'author': 'Bob Marley',\n",
       "  'text': \"“You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect—you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break—her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.”\",\n",
       "  'tags': ['love']},\n",
       " {'author': 'Dr. Seuss',\n",
       "  'text': '“I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.”',\n",
       "  'tags': ['fantasy']},\n",
       " {'author': 'Douglas Adams',\n",
       "  'text': '“I may not have gone where I intended to go, but I think I have ended up where I needed to be.”',\n",
       "  'tags': ['life', 'navigation']},\n",
       " {'author': 'Elie Wiesel',\n",
       "  'text': \"“The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.”\",\n",
       "  'tags': ['activism',\n",
       "   'apathy',\n",
       "   'hate',\n",
       "   'indifference',\n",
       "   'inspirational',\n",
       "   'love',\n",
       "   'opposite',\n",
       "   'philosophy']},\n",
       " {'author': 'Friedrich Nietzsche',\n",
       "  'text': '“It is not a lack of love, but a lack of friendship that makes unhappy marriages.”',\n",
       "  'tags': ['friendship',\n",
       "   'lack-of-friendship',\n",
       "   'lack-of-love',\n",
       "   'love',\n",
       "   'marriage',\n",
       "   'unhappy-marriage']},\n",
       " {'author': 'Mark Twain',\n",
       "  'text': '“Good friends, good books, and a sleepy conscience: this is the ideal life.”',\n",
       "  'tags': ['books', 'contentment', 'friends', 'friendship', 'life']},\n",
       " {'author': 'Allen Saunders',\n",
       "  'text': '“Life is what happens to us while we are making other plans.”',\n",
       "  'tags': ['fate', 'life', 'misattributed-john-lennon', 'planning', 'plans']},\n",
       " {'author': 'Albert Einstein',\n",
       "  'text': '“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n",
       "  'tags': ['change', 'deep-thoughts', 'thinking', 'world']},\n",
       " {'author': 'J.K. Rowling',\n",
       "  'text': '“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n",
       "  'tags': ['abilities', 'choices']},\n",
       " {'author': 'Albert Einstein',\n",
       "  'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n",
       "  'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles']},\n",
       " {'author': 'Jane Austen',\n",
       "  'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”',\n",
       "  'tags': ['aliteracy', 'books', 'classic', 'humor']},\n",
       " {'author': 'Marilyn Monroe',\n",
       "  'text': \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\",\n",
       "  'tags': ['be-yourself', 'inspirational']},\n",
       " {'author': 'Albert Einstein',\n",
       "  'text': '“Try not to become a man of success. Rather become a man of value.”',\n",
       "  'tags': ['adulthood', 'success', 'value']},\n",
       " {'author': 'André Gide',\n",
       "  'text': '“It is better to be hated for what you are than to be loved for what you are not.”',\n",
       "  'tags': ['life', 'love']},\n",
       " {'author': 'Thomas A. Edison',\n",
       "  'text': \"“I have not failed. I've just found 10,000 ways that won't work.”\",\n",
       "  'tags': ['edison', 'failure', 'inspirational', 'paraphrased']},\n",
       " {'author': 'Eleanor Roosevelt',\n",
       "  'text': \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\",\n",
       "  'tags': ['misattributed-eleanor-roosevelt']},\n",
       " {'author': 'Steve Martin',\n",
       "  'text': '“A day without sunshine is like, you know, night.”',\n",
       "  'tags': ['humor', 'obvious', 'simile']}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "file = open('demo1_quotes.json','r',encoding='UTF-8') \n",
    "# lines=json.load(file_object)\n",
    "# lines\n",
    "# 由于文件中有多行，直接读取会出现错误，因此一行一行读取\n",
    "data = []\n",
    "for line in file.readlines():\n",
    "    dic = json.loads(line)\n",
    "    data.append(dic)\n",
    "print('json文件中有%d行数据'%len(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
